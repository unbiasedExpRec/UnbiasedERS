<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" class="gr__shape2prog_csail_mit_edu"><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

              <meta name="viewport" content="width=device-width, initial-scale=1">    <link rel="shortcut icon" href="http://shape2prog.csail.mit.edu/images/favicon.ico">
        <meta name="description" content="Recommendation with Causality enhanced Natural Language Explanations">
        <meta name="keywords" content="Recommendation with Causality enhanced Natural Language Explanations">

        <title>Recommendation with Causality enhanced 
		Natural Language Explanations</title>
        <link rel="stylesheet" href="asset/font.css">
        <link rel="stylesheet" href="asset/main.css">

    </head>

    <body data-gr-c-s-loaded="true">

        <div class="outercontainer">
            <div class="container">

                <div class="content project_title">
                    <h1>Recommendation with Causality enhanced Natural Language Explanations</h1>
                </div>

                <div class="content project_headline">
                    <center><h2>
                      <font size="3">Anonymous Author(s)</font>&nbsp;&nbsp;
                   
                </div>


                


                <div class="content">
                    <div class="text">
                        <h1>1. Abstract</h1>
                        <p><font size=3>Explainable recommendation has recently attracted increasing attention from both academic and industry communities.
Among different explainable strategies, generating natural language explanations is an important method, which can deliver more informative, flexible and readable explanations to facilitate better user decisions. 
Despite effectiveness, existing models are mostly optimized based on the observational datasets, which can be skewed due to the selection or exposure biases.
To alleviate this problem, in this paper, we formulate the explainable recommendation task with a causal graph, and design an inverse propensity score (IPS) based model to generate unbiased explanations.
To be more specific, we firstly define an unbiased learning objective, and then leverage IPS to re-weight different samples, such that the underrepresented explanations can be valued more in the training process.
For more robust optimization, we enhance the above model by minimizing the maximum loss induced by the sample weights near the estimated IPS.
In addition, we analysis three types of potential unobserved confounders, and infer them to improve the accuracy of the original model.
By comparing with a series of state-of-the-art methods, we conduct extensive experiments based on three real-world datasets to demonstrate the effectiveness of our model.
			</font></p>
			    <h3>Contributions</h3>
                            <p><ul class="download">
			    <font size=3>
                            <li>We propose to build a causal framework to debias explainable recommender models, which, to the best of our knowledge, is the first time in the recommendation domain.</li>
			    <li>To achieve the above idea, we carefully design an IPS based model, where we not only design principled method to enhance the fault tolerance capability of the IPS estimation, but also analyze and model the potential latent confounders.</li>
			    <li>We conduct extensive experiments to demonstrate the effectiveness of our model. To promote this research direction and benefit the community, we have released our framework.</li>
                            </font>
                    </div>
                </div>
			
			
			
			
			
                <div class="content">
                    <div class="text">
                        <h1>2. Main Results</h1>
                    </div>

                    <div class="content project_headline">
					<div class="text">
                            <p><font size=3>Table 1: Performance comparison between our methods and baselines on explanation generation. For all metrics, the larger, the better. We implement our three methods based on NETE and PETER. For each dataset, bold fonts are used to mark the best performance in each module.</font></p>
                        </div>
                        <div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/exp_results.png" alt="result" style="margin:auto;max-width:90%">
			</div>
                    </div>		
                </div>
			
			
			
			
			
		<div class="content">
                    <div class="text">
                        <h1>3. Code and Datasets</h1>

						<h2> 3.1 Code <a href="https://drive.google.com/drive/folders/1a-VR4rIv5m-qseVnPX_2n210bkUyqxeJ">[link:Google Driver]</font></a></h2>
						
						<div class="content project_headline">
						<div class="text">
                            <p><font size=3>Table 2: Structure of the code files [main program].</font></p>
                        </div>
						<div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/cacf-code1.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
					
                        <div class="img" style="text-align:center">
						<div class="text">
                            <p><font size=3>Table 3: Structure of the code files [utils].</font></p>
                        </div>
                            <img class="img_responsive" src="asset/cacf-code2.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
                        </div>
                        <h2>3.2 Datasets <a href="https://drive.google.com/drive/folders/19tPFh4NZXTwoussEhcxN-EH3XQdjlsKl?usp=sharing">[link:Google Driver]</a></font></h2>
						<div class="content project_headline">
						<div class="text">
                            <p style="text-align:center"><font size=3>Table 3: Statistics of the datasets used in our experiments. D denotes the number of features contained in the datasets</font></p>
                        </div>
                        <div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/dataset.png" alt="result" style="margin:auto;max-width:70%">
                        </div>
                        
                        </div>
                    </div>
                </div>

			
			
			

                <div class="content">
                    <div class="text">
                        <h1>4. Usage</h1>
						<p> <font size=4>4.1. Download the code and dataset</font></p>
						<p> <font size=4>4.2. Run </font></p>
			    			<p> <font size=3>Take running PETER-D as an example:</p>
						<p> <font size=3>Run run_cacf.py.</p>
                        				<div class="img" style="text-align:center">
                            				<img class="img_responsive" src="asset/command.png" alt="result" style="margin:auto;max-width:83%">
                       					</div>
			    			<p> <font size=3>You can configure some training parameters through the command line.</p>
			    				<div class="content project_headline">
			    				<div class="text">
                            				<p style="text-align:center"><font size=3>Table 4: Parameters meanings</font></p>
                        				</div>
							<div class="img" style="text-align:center">
                            				<img class="img_responsive" src="asset/params.png" alt="result" style="margin:auto;max-width:75%">
                       					</div>
							</div>
						</font>
                    </div>
                </div>
               
			
			
                <div class="content">
                    <div class="text">
                        <h1>5. Detailed parameters search ranges</h1>
			<div class="content project_headline">
			<div class="text">
                	<p style="text-align:center"><font size=3>Table 5: The ranges of parameters. </font></p>
                        </div>			
			</div>
			<div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/range.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
                    </div>
                </div>

			
			

                <div class="content">
                    <div class="text">
                        <h1>6. Runtime Environment</h1>
						<ul class="download">
						<font size=3>
                            				<li><p>Linux System: 5.13.0-44-generic</p></li>
							<li><p>CPU: Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz</p></li>
							<li><p>GPU: NVIDIA Corporation Device 2204 (rev a1)</p></li>
                           				<li><p>GPU-Memory: 24G</p></li>
							<li><p>Python: 3.8.12</p></li>
							<li><p>Pytorch: 1.10.1</p></li>
							<li><p>CUDA: 11.3</p></li>
						</font>
                        </ul>
						
                    </div>
                </div>

<div id="download_plus_animation"></div></body></html>
